{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SourabhMagadum/Hindi-Sentiment-Analysis/blob/master/Hindi_sentiment_analysis1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "colab_type": "code",
        "id": "gxbgrTR5-t7r",
        "outputId": "33001976-8f4a-42f4-b30f-ea2068fb1e97"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.python.keras import Sequential\n",
        "from tensorflow.python.keras.layers import Dense, Embedding, LSTM, GRU \n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras import optimizers\n",
        "from tensorflow.python.keras import layers\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "PzMXc74SrhAw"
      },
      "outputs": [],
      "source": [
        "from numpy.random import seed\n",
        "seed(1)\n",
        "from numpy.random import seed\n",
        "seed(1)\n",
        "from tensorflow import set_random_seed\n",
        "set_random_seed(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "_ZISB5UF_x4Y"
      },
      "outputs": [],
      "source": [
        "import io\n",
        "df = pd.read_csv(io.BytesIO(uploaded['emotions.csv']))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "colab_type": "code",
        "id": "TuyzqoczAc4J",
        "outputId": "2357e6be-3707-4a5e-9bd5-ff0d6439c070"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentences</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>मेरे ट्रैन का बुकिंग फेल हो रहा है बार बार</td>\n",
              "      <td>angry</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>मेरे फ्लाइट  का बुकिंग फेल हो रहा है बार बार</td>\n",
              "      <td>angry</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>क्या बेकार की बातें कर रहे हो</td>\n",
              "      <td>angry</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>क्या बताओ यार मूड ही ख़राब है</td>\n",
              "      <td>angry</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>आप ऐसे कैसे मेरा पैसा काट सकते हो</td>\n",
              "      <td>angry</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       Sentences  Label\n",
              "0    मेरे ट्रैन का बुकिंग फेल हो रहा है बार बार   angry\n",
              "1  मेरे फ्लाइट  का बुकिंग फेल हो रहा है बार बार   angry\n",
              "2                 क्या बेकार की बातें कर रहे हो   angry\n",
              "3                  क्या बताओ यार मूड ही ख़राब है   angry\n",
              "4             आप ऐसे कैसे मेरा पैसा काट सकते हो   angry"
            ]
          },
          "execution_count": 5,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "colab_type": "code",
        "id": "i_mSkGSsA12b",
        "outputId": "5974070c-fbf3-4b9f-bb3e-84c9755679f2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(513, 2)"
            ]
          },
          "execution_count": 6,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "hpqLRMiiJJWm"
      },
      "outputs": [],
      "source": [
        "y = df[\"Label\"]\n",
        "X = df.drop([\"Label\"], axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "colab_type": "code",
        "id": "Kq9LdZSMBWKV",
        "outputId": "a30d82d5-1ea2-482e-ff75-1b9e8e7361b8"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentences</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>171</th>\n",
              "      <td>आये होये ! ! ! आज तो तूने दिल जीत लिया भाई</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>226</th>\n",
              "      <td>शुक्रिया तुम्हारा</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>यार बार बार इंडिका ही क्यों बुक होता है</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>ऐसे कैसे चैनल्स बंद कर दिए आप</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>167</th>\n",
              "      <td>वाह ! ! ! सस्ती चीज बता दी यार</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       Sentences\n",
              "171  आये होये ! ! ! आज तो तूने दिल जीत लिया भाई \n",
              "226                           शुक्रिया तुम्हारा \n",
              "24      यार बार बार इंडिका ही क्यों बुक होता है \n",
              "33                ऐसे कैसे चैनल्स बंद कर दिए आप \n",
              "167               वाह ! ! ! सस्ती चीज बता दी यार"
            ]
          },
          "execution_count": 8,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 70/15/15 train/test/val split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=1)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.15, random_state=1)\n",
        "\n",
        "X_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "ScF16hE0S8Z9"
      },
      "outputs": [],
      "source": [
        "tk = Tokenizer(filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{\"}~\\t\\n')\n",
        "\n",
        "all_sentences = X_train + X_test + X_val\n",
        "\n",
        "tk.fit_on_texts(X['Sentences'])\n",
        "\n",
        "# + 1 for unknown token\n",
        "vocab_size = len(tk.word_index) +1\n",
        "\n",
        "X_train_seq = tk.texts_to_sequences(X_train['Sentences'])\n",
        "X_test_seq = tk.texts_to_sequences(X_test['Sentences'])\n",
        "X_val_seq = tk.texts_to_sequences(X_val['Sentences'])\n",
        "# Initializing max length of sentence to 20 words\n",
        "max_length = 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "colab_type": "code",
        "id": "UreIQTGecPOI",
        "outputId": "603e4dca-f1c8-40b7-e4d8-b993d47e2985"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'10': 336,\n",
              " 'अंतिम': 292,\n",
              " 'अंदर': 606,\n",
              " 'अकाउंट': 47,\n",
              " 'अगले': 566,\n",
              " 'अगेंस्ट': 430,\n",
              " 'अच्छा': 27,\n",
              " 'अच्छी': 152,\n",
              " 'अच्छे': 269,\n",
              " 'अजीब': 399,\n",
              " 'अनसैटिस्फाइड': 640,\n",
              " 'अनुभव': 601,\n",
              " 'अपना': 224,\n",
              " 'अपनी': 340,\n",
              " 'अपने': 109,\n",
              " 'अप्प': 249,\n",
              " 'अब': 160,\n",
              " 'अबे': 93,\n",
              " 'अभी': 101,\n",
              " 'अरे': 51,\n",
              " 'अल्लाह': 285,\n",
              " 'अवेलेबल': 310,\n",
              " 'अहमदाबाद': 553,\n",
              " 'आ': 38,\n",
              " 'आई': 636,\n",
              " 'आए': 677,\n",
              " 'आएँगे': 593,\n",
              " 'आएगा': 175,\n",
              " 'आओ': 392,\n",
              " 'आखरी': 511,\n",
              " 'आखिरकार': 268,\n",
              " 'आगे': 304,\n",
              " 'आज': 60,\n",
              " 'आजका': 635,\n",
              " 'आता': 234,\n",
              " 'आती': 372,\n",
              " 'आने': 543,\n",
              " 'आप': 92,\n",
              " 'आपकी': 477,\n",
              " 'आपसे': 206,\n",
              " 'आय': 281,\n",
              " 'आया': 74,\n",
              " 'आये': 457,\n",
              " 'आर': 282,\n",
              " 'आश्चर्यचकित': 483,\n",
              " 'आस': 306,\n",
              " 'इंटरफ़ेस': 375,\n",
              " 'इंटरफ़ेस': 395,\n",
              " 'इंटेलीजेंट': 468,\n",
              " 'इंडिका': 353,\n",
              " 'इंतज़ार': 368,\n",
              " 'इडियट': 350,\n",
              " 'इतना': 90,\n",
              " 'इतनी': 154,\n",
              " 'इतने': 144,\n",
              " 'इत्ता': 439,\n",
              " 'इधर': 124,\n",
              " 'इन': 290,\n",
              " 'इनका': 329,\n",
              " 'इनके': 219,\n",
              " 'इम्प्रूव': 642,\n",
              " 'इम्प्रेस्सड': 471,\n",
              " 'इलाके': 564,\n",
              " 'इस': 89,\n",
              " 'इसके': 665,\n",
              " 'इसको': 580,\n",
              " 'इसे': 363,\n",
              " 'इस्तेमाल': 576,\n",
              " 'उतना': 652,\n",
              " 'उतार': 659,\n",
              " 'उन्दा': 472,\n",
              " 'उबर': 545,\n",
              " 'उम्मीद': 104,\n",
              " 'उल्लू': 435,\n",
              " 'उस': 596,\n",
              " 'उसके': 505,\n",
              " 'एक': 11,\n",
              " 'एकदम': 419,\n",
              " 'एक्सपायर': 513,\n",
              " 'एक्सपायरी': 526,\n",
              " 'एक्सपीरिएंस': 618,\n",
              " 'एक्सपीरियंस': 619,\n",
              " 'एक्सपेक्टिंग': 638,\n",
              " 'एक्सपेक्टेशंस': 325,\n",
              " 'एग्जीक्यूटिव': 332,\n",
              " 'एप': 37,\n",
              " 'एप्प': 50,\n",
              " 'एम': 470,\n",
              " 'ऐड': 503,\n",
              " 'ऐप': 201,\n",
              " 'ऐसा': 134,\n",
              " 'ऐसी': 482,\n",
              " 'ऐसे': 125,\n",
              " 'ऑटो': 198,\n",
              " 'ऑन': 246,\n",
              " 'ऑफ': 243,\n",
              " 'ऑफर': 270,\n",
              " 'ऑफ़': 406,\n",
              " 'ओए': 149,\n",
              " 'ओय': 436,\n",
              " 'ओयो': 527,\n",
              " 'और': 35,\n",
              " 'कंप्लेन': 431,\n",
              " 'कट': 507,\n",
              " 'कन्फर्म': 531,\n",
              " 'कन्फुसिंग': 374,\n",
              " 'कब': 54,\n",
              " 'कभी': 113,\n",
              " 'कम': 182,\n",
              " 'कमल': 459,\n",
              " 'कमाल': 474,\n",
              " 'कमीने': 418,\n",
              " 'कम्प्लेन': 220,\n",
              " 'कर': 6,\n",
              " 'करके': 111,\n",
              " 'करता': 184,\n",
              " 'करते': 412,\n",
              " 'करदो': 497,\n",
              " 'करदोगे': 555,\n",
              " 'करना': 86,\n",
              " 'करनी': 163,\n",
              " 'करने': 53,\n",
              " 'करवाओगे': 369,\n",
              " 'करा': 177,\n",
              " 'कराओ': 362,\n",
              " 'करू': 303,\n",
              " 'करूँ': 127,\n",
              " 'करेगा': 351,\n",
              " 'करो': 70,\n",
              " 'कल': 305,\n",
              " 'कस्टमर': 680,\n",
              " 'कहा': 137,\n",
              " 'कहाँ': 346,\n",
              " 'कही': 573,\n",
              " 'का': 14,\n",
              " 'काट': 330,\n",
              " 'काफी': 63,\n",
              " 'काबिल': 490,\n",
              " 'काम': 20,\n",
              " 'कारण': 328,\n",
              " 'काश': 327,\n",
              " 'कि': 448,\n",
              " 'कितना': 69,\n",
              " 'कितनी': 170,\n",
              " 'कितने': 229,\n",
              " 'किया': 80,\n",
              " 'किसी': 426,\n",
              " 'किस्मत': 662,\n",
              " 'की': 12,\n",
              " 'कुछ': 41,\n",
              " 'कुत्ते': 440,\n",
              " 'कुशल': 485,\n",
              " 'कूपन': 266,\n",
              " 'के': 18,\n",
              " 'केयर': 681,\n",
              " 'कैंसिल': 138,\n",
              " 'कैब': 15,\n",
              " 'कैसा': 166,\n",
              " 'कैसी': 366,\n",
              " 'कैसे': 30,\n",
              " 'कॉल': 682,\n",
              " 'को': 77,\n",
              " 'कोई': 79,\n",
              " 'कोटि': 146,\n",
              " 'कोसिस': 586,\n",
              " 'कौन': 133,\n",
              " 'क्या': 2,\n",
              " 'क्यों': 45,\n",
              " 'क्रोधित': 379,\n",
              " 'क्लैरिटी': 495,\n",
              " 'खराब': 136,\n",
              " 'खर्च': 585,\n",
              " 'ख़राब': 663,\n",
              " 'खा': 572,\n",
              " 'खाना': 213,\n",
              " 'खाने': 547,\n",
              " 'खुद': 387,\n",
              " 'खुश': 103,\n",
              " 'खूब': 447,\n",
              " 'खूबसूरत': 461,\n",
              " 'खोजो': 523,\n",
              " 'गंदगी': 611,\n",
              " 'गई': 197,\n",
              " 'गए': 100,\n",
              " 'गधा': 178,\n",
              " 'गधे': 168,\n",
              " 'गन्दा': 320,\n",
              " 'गन्दी': 607,\n",
              " 'गया': 23,\n",
              " 'गयी': 95,\n",
              " 'गर्मी': 569,\n",
              " 'गलत': 598,\n",
              " 'गलती': 676,\n",
              " 'गवार': 227,\n",
              " 'गांड': 630,\n",
              " 'गांडू': 383,\n",
              " 'गाली': 626,\n",
              " 'गाड़ी': 538,\n",
              " 'गुजरे': 424,\n",
              " 'गुड': 155,\n",
              " 'गुस्सा': 367,\n",
              " 'ग्रेट': 469,\n",
              " 'ग्वालियर': 554,\n",
              " 'गज़ब': 463,\n",
              " 'घंटा': 612,\n",
              " 'घटिया': 108,\n",
              " 'घर': 456,\n",
              " 'घूमने': 574,\n",
              " 'चल': 116,\n",
              " 'चलते': 575,\n",
              " 'चलेंगे': 299,\n",
              " 'चलेगा': 210,\n",
              " 'चलेगी': 529,\n",
              " 'चलो': 581,\n",
              " 'चाप': 226,\n",
              " 'चाल': 558,\n",
              " 'चालू': 499,\n",
              " 'चाहिए': 158,\n",
              " 'चीज': 235,\n",
              " 'चीज़': 454,\n",
              " 'चीज़': 180,\n",
              " 'चुका': 408,\n",
              " 'चुतियापा': 390,\n",
              " 'चुप': 225,\n",
              " 'चूतिया': 410,\n",
              " 'चूतिये': 427,\n",
              " 'चूतियों': 378,\n",
              " 'चेक': 316,\n",
              " 'चैनल': 188,\n",
              " 'चैनल्स': 88,\n",
              " 'चोर': 355,\n",
              " 'जगह': 462,\n",
              " 'जय': 475,\n",
              " 'जरा': 516,\n",
              " 'जल्दी': 68,\n",
              " 'जवाब': 287,\n",
              " 'ज़्यादा': 536,\n",
              " 'जा': 130,\n",
              " 'जाऊं': 487,\n",
              " 'जाए': 528,\n",
              " 'जाएंगे': 514,\n",
              " 'जाएगा': 300,\n",
              " 'जाता': 259,\n",
              " 'जाती': 592,\n",
              " 'जाते': 584,\n",
              " 'जायेंगे': 520,\n",
              " 'जीत': 267,\n",
              " 'जीना': 633,\n",
              " 'जैसा': 253,\n",
              " 'जॉब': 460,\n",
              " 'जो': 185,\n",
              " 'जोरदार': 478,\n",
              " 'ज्यादा': 256,\n",
              " 'टट्टी': 380,\n",
              " 'टाइम': 71,\n",
              " 'टिकट': 52,\n",
              " 'टिकट्स': 295,\n",
              " 'टीवी': 344,\n",
              " 'टेंपरेचर': 565,\n",
              " 'टैक्स': 623,\n",
              " 'टोल': 622,\n",
              " 'ट्रेन': 120,\n",
              " 'ट्रैन': 43,\n",
              " 'ठण्ड': 570,\n",
              " 'ठाक': 594,\n",
              " 'ठीक': 313,\n",
              " 'डलवा': 349,\n",
              " 'डलवाऊँगा': 354,\n",
              " 'डलवाने': 262,\n",
              " 'डिटेल्स': 357,\n",
              " 'डिलीवर': 669,\n",
              " 'डिलीवरी': 434,\n",
              " 'डिले': 319,\n",
              " 'डिश': 343,\n",
              " 'डिसिप्लिंड': 621,\n",
              " 'डिस्काउंट': 493,\n",
              " 'डील': 142,\n",
              " 'डेट': 301,\n",
              " 'ड्राइवर': 72,\n",
              " 'ढंग': 651,\n",
              " 'तंग': 407,\n",
              " 'तक': 44,\n",
              " 'तबसे': 388,\n",
              " 'तापमान': 530,\n",
              " 'तारीख': 512,\n",
              " 'तारीफ': 489,\n",
              " 'तिथि': 525,\n",
              " 'तुझे': 370,\n",
              " 'तुम': 17,\n",
              " 'तुमको': 422,\n",
              " 'तुमने': 61,\n",
              " 'तुमसे': 62,\n",
              " 'तुम्हरा': 263,\n",
              " 'तुम्हारा': 75,\n",
              " 'तुम्हारी': 232,\n",
              " 'तुम्हारे': 99,\n",
              " 'तुरंत': 174,\n",
              " 'तू': 87,\n",
              " 'तूने': 81,\n",
              " 'तेरा': 347,\n",
              " 'तेरे': 237,\n",
              " 'तो': 34,\n",
              " 'तोह': 241,\n",
              " 'थक': 568,\n",
              " 'था': 16,\n",
              " 'थी': 39,\n",
              " 'थे': 588,\n",
              " 'थैंकयू': 491,\n",
              " 'थैंक्यू': 278,\n",
              " 'थैंक्स': 271,\n",
              " 'थोड़ा': 625,\n",
              " 'द': 473,\n",
              " 'दम': 250,\n",
              " 'दाद': 479,\n",
              " 'दिआ': 660,\n",
              " 'दिए': 231,\n",
              " 'दिक्कत': 683,\n",
              " 'दिखा': 208,\n",
              " 'दिखाओ': 307,\n",
              " 'दिन': 298,\n",
              " 'दिमाग': 128,\n",
              " 'दिया': 57,\n",
              " 'दिल': 196,\n",
              " 'दिल्ली': 212,\n",
              " 'दिवाली': 589,\n",
              " 'दी': 140,\n",
              " 'दीवार': 417,\n",
              " 'दुखी': 685,\n",
              " 'दुनिया': 409,\n",
              " 'दू': 506,\n",
              " 'दूँ': 445,\n",
              " 'दे': 131,\n",
              " 'देखता': 504,\n",
              " 'देखे': 577,\n",
              " 'देखें': 582,\n",
              " 'देता': 480,\n",
              " 'देते': 429,\n",
              " 'देर': 608,\n",
              " 'दो': 64,\n",
              " 'दोस्त': 450,\n",
              " 'ध': 401,\n",
              " 'धन्यवाद': 58,\n",
              " 'धुप': 549,\n",
              " 'धोखा': 678,\n",
              " 'न': 254,\n",
              " 'नंबर': 147,\n",
              " 'नही': 318,\n",
              " 'नहीं': 4,\n",
              " 'ना': 539,\n",
              " 'नाइस': 455,\n",
              " 'नाखुश': 655,\n",
              " 'नागपुर': 510,\n",
              " 'नाराज': 321,\n",
              " 'नालायक': 358,\n",
              " 'निकल': 339,\n",
              " 'निकला': 595,\n",
              " 'निराश': 322,\n",
              " 'निराशाजनक': 600,\n",
              " 'ने': 56,\n",
              " 'पता': 211,\n",
              " 'पर': 141,\n",
              " 'परफॉर्मेंस': 629,\n",
              " 'परसों': 311,\n",
              " 'परिवार': 502,\n",
              " 'परेशान': 114,\n",
              " 'पल्ले': 442,\n",
              " 'पसंद': 653,\n",
              " 'पहले': 189,\n",
              " 'पहुंची': 657,\n",
              " 'पहुंचेगी': 560,\n",
              " 'पा': 389,\n",
              " 'पागल': 165,\n",
              " 'पागलपंती': 396,\n",
              " 'पाता': 664,\n",
              " 'पायेगा': 385,\n",
              " 'पास': 110,\n",
              " 'पीड़ित': 673,\n",
              " 'पीड़ित': 674,\n",
              " 'पूल': 649,\n",
              " 'पे': 317,\n",
              " 'पेमेंट': 533,\n",
              " 'पैक': 169,\n",
              " 'पैक्स': 228,\n",
              " 'पैसा': 106,\n",
              " 'पैसे': 29,\n",
              " 'प्रफुल्लित': 481,\n",
              " 'प्रसन्न': 465,\n",
              " 'प्राइस': 535,\n",
              " 'प्रॉब्लम': 334,\n",
              " 'प्लान': 167,\n",
              " 'प्लीज': 521,\n",
              " 'पड़ेगी': 164,\n",
              " 'फट': 579,\n",
              " 'फटा': 578,\n",
              " 'फस': 373,\n",
              " 'फसता': 441,\n",
              " 'फसने': 670,\n",
              " 'फालतू': 394,\n",
              " 'फिर': 238,\n",
              " 'फिरसे': 604,\n",
              " 'फिलहाल': 544,\n",
              " 'फील': 614,\n",
              " 'फेल': 216,\n",
              " 'फ्लाइट': 28,\n",
              " 'फ्लाइट्स': 590,\n",
              " 'बंद': 135,\n",
              " 'बंध': 391,\n",
              " 'बकवास': 132,\n",
              " 'बको': 421,\n",
              " 'बचा': 297,\n",
              " 'बच्चे': 333,\n",
              " 'बढ़िया': 204,\n",
              " 'बढू': 534,\n",
              " 'बतमीज़ी': 371,\n",
              " 'बता': 222,\n",
              " 'बताई': 236,\n",
              " 'बताएंगे': 302,\n",
              " 'बताओ': 105,\n",
              " 'बताते': 365,\n",
              " 'बताया': 599,\n",
              " 'बताये': 515,\n",
              " 'बदतमीजी': 627,\n",
              " 'बद्तमीज़': 647,\n",
              " 'बना': 397,\n",
              " 'बर्ताव': 641,\n",
              " 'बर्बाद': 386,\n",
              " 'बस': 356,\n",
              " 'बहनचोद': 186,\n",
              " 'बहुत': 8,\n",
              " 'बात': 55,\n",
              " 'बातें': 217,\n",
              " 'बार': 22,\n",
              " 'बारिश': 153,\n",
              " 'बारे': 548,\n",
              " 'बाहर': 312,\n",
              " 'बिलकुल': 261,\n",
              " 'बिहेवियर': 617,\n",
              " 'बीच': 658,\n",
              " 'बुक': 19,\n",
              " 'बुकिंग': 65,\n",
              " 'बुरा': 620,\n",
              " 'बुलाओ': 542,\n",
              " 'बे': 173,\n",
              " 'बेंगलुरु': 567,\n",
              " 'बेकार': 66,\n",
              " 'बेज़त्ति': 403,\n",
              " 'बेटर': 645,\n",
              " 'बेवक़ूफ़': 416,\n",
              " 'बेवकूफ': 438,\n",
              " 'बेशिस्त': 646,\n",
              " 'बेस': 500,\n",
              " 'बेस्ट': 200,\n",
              " 'बेहतर': 650,\n",
              " 'बेहतरीन': 273,\n",
              " 'बैंगलोर': 151,\n",
              " 'बैलेंस': 107,\n",
              " 'बॉट': 423,\n",
              " 'बोल': 345,\n",
              " 'बोलनी': 382,\n",
              " 'बोला': 171,\n",
              " 'बोले': 381,\n",
              " 'बोलो': 671,\n",
              " 'बोलोगे': 230,\n",
              " 'बड़ी': 537,\n",
              " 'बड़े': 283,\n",
              " 'बढ़िया': 82,\n",
              " 'भरवाया': 624,\n",
              " 'भाई': 36,\n",
              " 'भी': 48,\n",
              " 'भूक': 667,\n",
              " 'भोस्डिके': 433,\n",
              " 'भोसड़ीके': 247,\n",
              " 'मंगल': 486,\n",
              " 'मई': 672,\n",
              " 'मख्खन': 446,\n",
              " 'मच': 279,\n",
              " 'मज़ा': 202,\n",
              " 'मजा': 289,\n",
              " 'मत': 172,\n",
              " 'मदद': 122,\n",
              " 'मन': 275,\n",
              " 'मर': 179,\n",
              " 'मस्त': 199,\n",
              " 'महीने': 296,\n",
              " 'मादरचोद': 248,\n",
              " 'मार': 631,\n",
              " 'माशा': 284,\n",
              " 'मिनट': 552,\n",
              " 'मिल': 83,\n",
              " 'मिला': 190,\n",
              " 'मिली': 193,\n",
              " 'मिलेंगे': 684,\n",
              " 'मुंबई': 209,\n",
              " 'मुझसे': 161,\n",
              " 'मुझे': 32,\n",
              " 'मूड': 218,\n",
              " 'मे': 181,\n",
              " 'में': 9,\n",
              " 'मेरा': 26,\n",
              " 'मेरी': 40,\n",
              " 'मेरे': 21,\n",
              " 'मेहरबानी': 476,\n",
              " 'मेहेंगा': 432,\n",
              " 'मेहेंगी': 591,\n",
              " 'मेेरे': 546,\n",
              " 'मै': 24,\n",
              " 'मैं': 73,\n",
              " 'मैंने': 223,\n",
              " 'मैन': 404,\n",
              " 'मोबाइल': 453,\n",
              " 'मोर': 639,\n",
              " 'मौसम': 97,\n",
              " 'मज़ा': 115,\n",
              " 'मज़ेदार': 205,\n",
              " 'यह': 143,\n",
              " 'यहाँ': 315,\n",
              " 'या': 518,\n",
              " 'यात्रा': 203,\n",
              " 'यार': 5,\n",
              " 'यारा': 451,\n",
              " 'यीपी': 119,\n",
              " 'यू': 157,\n",
              " 'यूस': 494,\n",
              " 'यूज़लेस': 240,\n",
              " 'ये': 7,\n",
              " 'रख': 342,\n",
              " 'रखा': 244,\n",
              " 'रखी': 632,\n",
              " 'रखो': 341,\n",
              " 'रजिस्टर': 264,\n",
              " 'रह': 376,\n",
              " 'रहा': 25,\n",
              " 'रही': 239,\n",
              " 'रहे': 67,\n",
              " 'राशि': 517,\n",
              " 'रास्ता': 364,\n",
              " 'रास्ते': 587,\n",
              " 'रिचार्ज': 42,\n",
              " 'रिवर्ट': 361,\n",
              " 'रिस्पांस': 398,\n",
              " 'रीस्टार्ट': 291,\n",
              " 'रेट': 255,\n",
              " 'रेटिंग': 563,\n",
              " 'लंड': 252,\n",
              " 'लग': 183,\n",
              " 'लगता': 191,\n",
              " 'लगने': 550,\n",
              " 'लगा': 207,\n",
              " 'लगाते': 215,\n",
              " 'लगी': 668,\n",
              " 'लव': 492,\n",
              " 'लाओ': 644,\n",
              " 'लाजवाब': 102,\n",
              " 'लास्ट': 524,\n",
              " 'लिए': 46,\n",
              " 'लिया': 150,\n",
              " 'लूं': 242,\n",
              " 'लूंगा': 666,\n",
              " 'लूज़र': 414,\n",
              " 'लेकिन': 337,\n",
              " 'लेगस्पेस': 605,\n",
              " 'लेट': 532,\n",
              " 'लॉक': 428,\n",
              " 'लोकेशन': 324,\n",
              " 'लौटने': 508,\n",
              " 'लौटा': 352,\n",
              " 'लौड़े': 348,\n",
              " 'वजह': 402,\n",
              " 'वह': 156,\n",
              " 'वही': 498,\n",
              " 'वाओ': 118,\n",
              " 'वाकई': 488,\n",
              " 'वापस': 214,\n",
              " 'वाला': 233,\n",
              " 'वाली': 112,\n",
              " 'वाले': 98,\n",
              " 'वालों': 616,\n",
              " 'वाह': 59,\n",
              " 'वाहियात': 257,\n",
              " 'वाहियाद': 251,\n",
              " 'वूहू': 265,\n",
              " 'वेबसाइट': 384,\n",
              " 'वेस्ट': 393,\n",
              " 'वैरी': 277,\n",
              " 'वॉस': 637,\n",
              " 'वो': 411,\n",
              " 'व्यू': 628,\n",
              " 'व्हाट': 400,\n",
              " 'शाबाश': 286,\n",
              " 'शिकायत': 377,\n",
              " 'शिट': 326,\n",
              " 'शुक्रिया': 145,\n",
              " 'संतुष्ट': 449,\n",
              " 'संभाऊंना': 509,\n",
              " 'सकता': 126,\n",
              " 'सकती': 679,\n",
              " 'सकते': 85,\n",
              " 'सच': 496,\n",
              " 'सड़ा': 603,\n",
              " 'सबसे': 96,\n",
              " 'समझ': 49,\n",
              " 'समझते': 415,\n",
              " 'समझदार': 484,\n",
              " 'समझा': 437,\n",
              " 'समय': 260,\n",
              " 'सर्विस': 31,\n",
              " 'सवाल': 561,\n",
              " 'सस्ता': 314,\n",
              " 'सस्ती': 192,\n",
              " 'सही': 76,\n",
              " 'सा': 187,\n",
              " 'सारथि': 272,\n",
              " 'सारथी': 84,\n",
              " 'सारे': 583,\n",
              " 'साले': 129,\n",
              " 'सी': 501,\n",
              " 'सीनियर': 331,\n",
              " 'सुखद': 610,\n",
              " 'सुधार': 643,\n",
              " 'सुनाओ': 557,\n",
              " 'सुन्दर': 274,\n",
              " 'सुबह': 562,\n",
              " 'सुहाना': 571,\n",
              " 'से': 10,\n",
              " 'सेफ': 613,\n",
              " 'सैटिस्फाइड': 615,\n",
              " 'सॉरी': 675,\n",
              " 'सॉल्व': 335,\n",
              " 'सो': 280,\n",
              " 'स्टाफ': 323,\n",
              " 'स्टार': 541,\n",
              " 'स्टे': 656,\n",
              " 'स्टेटस': 308,\n",
              " 'स्टेशन': 559,\n",
              " 'स्मार्ट': 466,\n",
              " 'स्विमिंग': 648,\n",
              " 'स्वीट': 467,\n",
              " 'हंसते': 288,\n",
              " 'हने': 405,\n",
              " 'हम': 276,\n",
              " 'हमरी': 609,\n",
              " 'हमारा': 602,\n",
              " 'हमे': 443,\n",
              " 'हमें': 597,\n",
              " 'हमेशा': 258,\n",
              " 'हराम': 634,\n",
              " 'हरामजादे': 425,\n",
              " 'हरामी': 413,\n",
              " 'हरामज़ादे': 420,\n",
              " 'हल': 338,\n",
              " 'हा': 195,\n",
              " 'हाल': 309,\n",
              " 'हालचाल': 556,\n",
              " 'हिसाब': 293,\n",
              " 'ही': 33,\n",
              " 'हीरो': 452,\n",
              " 'हु': 78,\n",
              " 'हुआ': 91,\n",
              " 'हुई': 121,\n",
              " 'हुर्रे': 148,\n",
              " 'हू': 139,\n",
              " 'हूँ': 117,\n",
              " 'हूं': 661,\n",
              " 'हेल्प': 123,\n",
              " 'हेल्पिंग': 464,\n",
              " 'है': 1,\n",
              " 'हैं': 359,\n",
              " 'हो': 3,\n",
              " 'होए': 194,\n",
              " 'होगा': 94,\n",
              " 'होटल': 13,\n",
              " 'होटेल': 522,\n",
              " 'होता': 176,\n",
              " 'होते': 360,\n",
              " 'होने': 159,\n",
              " 'होये': 458,\n",
              " 'ख़तम': 221,\n",
              " 'ख़त्म': 519,\n",
              " 'ख़राब': 162,\n",
              " 'ख़ास': 654,\n",
              " 'ख़ुशी': 444,\n",
              " 'फ़क': 245,\n",
              " '२': 294,\n",
              " '३': 540,\n",
              " '५': 551}"
            ]
          },
          "execution_count": 10,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tk.word_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "colab_type": "code",
        "id": "G0fHuNn8clLk",
        "outputId": "65d26a83-29d9-4f8d-83de-72c739c81118"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "686\n"
          ]
        }
      ],
      "source": [
        "print(vocab_size)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "colab_type": "code",
        "id": "X_bXPd9Kd0Ph",
        "outputId": "eb556333-ed6c-466a-f8a8-9cb14f56a2c2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[457, 458, 60, 34, 81, 196, 267, 150, 36],\n",
              " [145, 75],\n",
              " [5, 22, 22, 353, 33, 45, 19, 176, 1],\n",
              " [125, 30, 88, 135, 6, 231, 92],\n",
              " [59, 192, 235, 222, 140, 5],\n",
              " [51, 7, 30, 94, 5],\n",
              " [2, 459, 6, 57, 81],\n",
              " [99, 402, 10, 403, 3, 95, 40],\n",
              " [5, 54, 94, 42, 21, 47, 14],\n",
              " [11, 147, 270, 190, 1],\n",
              " [305, 12, 212, 10, 209, 12, 79, 43, 52, 1],\n",
              " [7, 2, 132, 1],\n",
              " [223, 336, 22, 220, 12, 1, 337, 41, 338, 4, 339, 25],\n",
              " [13, 40, 325, 18, 293, 10, 4, 16],\n",
              " [40, 43, 71, 10, 116, 239, 1, 539],\n",
              " [149, 11, 65, 6, 131, 15, 12],\n",
              " [96, 182, 71, 550, 112, 120, 105],\n",
              " [15, 98, 56, 161, 651, 10, 55, 4, 12],\n",
              " [93, 42, 6, 225, 226, 10],\n",
              " [51, 7, 88, 45, 4, 38, 25, 427],\n",
              " [240],\n",
              " [13, 10, 628, 27, 4, 16],\n",
              " [2, 26, 11, 20, 555],\n",
              " [5, 2, 132, 6, 67, 3, 17],\n",
              " [2, 132, 228, 359],\n",
              " [122, 18, 46, 58],\n",
              " [2, 478, 20, 80, 1, 36],\n",
              " [196, 267, 150, 81],\n",
              " [40, 43, 14, 308, 211, 70],\n",
              " [124, 153, 121, 39, 2, 562],\n",
              " [113, 34, 20, 18, 392, 17],\n",
              " [28, 9, 547, 18, 46, 48, 41, 19, 6, 64],\n",
              " [13, 34, 102, 1],\n",
              " [11, 545, 19, 70],\n",
              " [29, 262, 18, 46, 58, 21, 5],\n",
              " [2, 73, 88, 503, 6, 126, 117],\n",
              " [32, 62, 7, 104, 4, 39],\n",
              " [17, 426, 20, 18, 4, 3, 186],\n",
              " [182, 246, 404],\n",
              " [15, 543, 9, 35, 69, 71, 1],\n",
              " [40, 203, 485, 486, 39, 58],\n",
              " [68, 6, 5, 87, 42, 348],\n",
              " [24, 34, 8, 103, 117, 7, 50, 494, 111],\n",
              " [390, 391, 70, 75],\n",
              " [148, 199, 15, 83, 95],\n",
              " [2, 26, 28, 246, 71, 1],\n",
              " [109, 92, 77, 49, 2, 244, 1, 81, 440],\n",
              " [252, 253, 20, 80, 61],\n",
              " [21, 47, 14, 107, 515, 516],\n",
              " [2, 5, 160, 44, 106, 4, 74],\n",
              " [269, 65, 18, 46, 58],\n",
              " [29, 508, 12, 2, 509, 1],\n",
              " [143, 34, 8, 27, 201, 1],\n",
              " [636, 637, 638, 639],\n",
              " [8, 33, 600, 601, 16, 602],\n",
              " [7, 201, 41, 654, 4, 1],\n",
              " [22, 22, 11, 33, 180, 381, 130, 67, 3],\n",
              " [148, 2, 142, 193, 1],\n",
              " [2, 309, 558, 1],\n",
              " [87, 178, 1, 2],\n",
              " [2, 371, 1, 5],\n",
              " [7, 166, 108, 167, 1],\n",
              " [101, 44, 129, 56, 434, 4, 140],\n",
              " [66, 167, 1, 329],\n",
              " [2, 55, 1, 5, 82, 13, 83, 23],\n",
              " [69, 106, 1, 21, 47, 9],\n",
              " [7, 13, 14, 535, 90, 536, 45, 208, 25, 1],\n",
              " [27, 91, 47, 135, 4, 91],\n",
              " [75, 79, 287, 4, 84],\n",
              " [218, 243, 6, 57],\n",
              " [26, 11, 561, 1],\n",
              " [2, 61, 213, 572, 150],\n",
              " [2, 394, 395, 1, 99, 50, 14],\n",
              " [79, 20, 18, 4, 3, 17],\n",
              " [13, 77, 170, 563, 193, 1],\n",
              " [21, 77, 109, 306, 110, 12, 13, 307],\n",
              " [2, 257, 1, 5],\n",
              " [11, 147, 20, 80, 1, 36, 81],\n",
              " [488, 489, 18, 490, 1],\n",
              " [31, 642, 70],\n",
              " [50, 14, 629, 8, 136, 1],\n",
              " [42, 53, 18, 46, 58, 21, 452],\n",
              " [60, 14, 530, 2, 1],\n",
              " [291, 53, 317, 48, 4, 3, 25],\n",
              " [54, 44, 299, 144, 29, 9],\n",
              " [263, 146, 146, 58, 26, 453, 147, 264, 53, 18, 46],\n",
              " [58, 21, 36],\n",
              " [609, 203, 610, 4, 39],\n",
              " [134, 183, 25, 1, 417, 10, 55, 6, 25, 78],\n",
              " [32, 8, 367, 38, 25, 1],\n",
              " [155, 460],\n",
              " [2, 76, 37, 1, 7],\n",
              " [144, 20, 29, 9, 90, 88],\n",
              " [26, 13, 9, 656, 27, 4, 16],\n",
              " [551, 552, 9, 198, 19, 6, 85, 3, 2],\n",
              " [439, 114, 24, 189, 113, 4, 91],\n",
              " [60, 14, 97, 166, 1],\n",
              " [17, 283, 205, 3],\n",
              " [17, 35, 645, 6, 85, 3],\n",
              " [580, 48, 11, 22, 316, 86, 158],\n",
              " [65, 30, 94],\n",
              " [76, 1],\n",
              " [148, 11, 147, 266, 83, 23],\n",
              " [24, 304, 30, 534],\n",
              " [8, 447],\n",
              " [196, 103, 6, 57, 81],\n",
              " [491, 84, 281, 492, 157],\n",
              " [5, 28, 56, 633, 634, 6, 231, 1],\n",
              " [289, 38, 23, 5],\n",
              " [5, 21, 29, 214, 54, 684],\n",
              " [170, 22, 11, 33, 180, 382, 164],\n",
              " [124, 10, 65, 45, 4, 3, 25, 1],\n",
              " [17, 43, 14, 52, 19, 85, 3],\n",
              " [8, 569, 1, 5, 315],\n",
              " [32, 41, 49, 9, 4, 38, 25, 1],\n",
              " [15, 72, 8, 464, 16],\n",
              " [99, 20, 14, 79, 287, 4, 84, 286],\n",
              " [185, 171, 411, 45, 4, 412, 3],\n",
              " [292, 525, 2, 1, 21, 47, 135, 159, 12],\n",
              " [166, 1, 87],\n",
              " [278, 277, 279],\n",
              " [130, 4, 177, 25, 73, 42],\n",
              " [160, 2, 127],\n",
              " [290, 88, 12, 495, 496, 9, 8, 152, 1],\n",
              " [581, 143, 111, 582],\n",
              " [21, 43, 14, 65, 216, 3, 25, 1, 22, 22],\n",
              " [200, 3, 17],\n",
              " [7, 15, 233, 137, 179, 23],\n",
              " [265],\n",
              " [24, 62, 8, 379, 78],\n",
              " [24, 615, 4, 78],\n",
              " [58, 272],\n",
              " [263, 146, 146, 58, 26, 47, 264, 53, 18, 46],\n",
              " [62, 79, 20, 254, 176, 247],\n",
              " [240, 37],\n",
              " [2, 414, 187, 37, 1],\n",
              " [102, 462, 16, 156],\n",
              " [370, 11, 22, 73, 49, 4, 234, 2],\n",
              " [52, 531, 1, 2],\n",
              " [13, 133, 10, 564, 9, 1],\n",
              " [129, 26, 106, 54, 44, 175],\n",
              " [43, 56, 630, 631, 6, 632, 1],\n",
              " [8, 115, 74],\n",
              " [90, 27, 31, 57, 34, 444, 10, 24, 35, 29, 131, 445],\n",
              " [21, 47, 9, 69, 107, 297, 1],\n",
              " [311, 14, 79, 28, 295, 307, 553, 10, 554, 14],\n",
              " [96, 314, 28, 14, 52, 19, 6, 64, 124, 10, 209, 14],\n",
              " [144, 29, 9, 229, 298, 299],\n",
              " [278, 280, 279],\n",
              " [8, 33, 132, 384, 1, 75, 36],\n",
              " [68, 349, 21, 29, 350],\n",
              " [8, 82, 91, 448, 29, 260, 10, 189, 38, 100],\n",
              " [157, 282, 155],\n",
              " [149, 194],\n",
              " [17, 241, 63, 468, 3],\n",
              " [99, 20, 12, 479, 480, 117],\n",
              " [59, 102],\n",
              " [400, 401, 245],\n",
              " [35, 2, 2, 184, 1, 7, 37],\n",
              " [388, 11, 20, 4, 6, 389, 67, 3, 17],\n",
              " [313, 594, 50, 191, 1],\n",
              " [224, 169, 109, 110, 342],\n",
              " [100, 424, 3, 17, 425],\n",
              " [7, 88, 14, 255, 90, 256, 45, 6, 429, 1, 22, 22],\n",
              " [89, 31, 10, 63, 321, 78, 24],\n",
              " [597, 206, 7, 104, 4, 39],\n",
              " [60, 14, 97, 8, 82, 1, 5],\n",
              " [103, 91, 73],\n",
              " [90, 432, 45, 433],\n",
              " [40, 28, 532, 45, 121, 1],\n",
              " [245, 406],\n",
              " [84, 122, 70],\n",
              " [60, 34, 63, 27, 270, 116, 67],\n",
              " [15, 18, 72, 56, 32, 658, 9, 33, 659, 660],\n",
              " [35, 69, 368, 369, 36],\n",
              " [7, 34, 27, 1],\n",
              " [11, 15, 19, 497],\n",
              " [17, 113, 41, 415, 33, 4, 3],\n",
              " [13, 9, 648, 649, 35, 22, 4, 16, 5],\n",
              " [60, 44, 12, 96, 66, 31, 39],\n",
              " [393, 243, 71],\n",
              " [276, 76, 587, 130, 67, 588],\n",
              " [227, 37],\n",
              " [69, 603, 13, 16],\n",
              " [61, 32, 8, 322, 6, 57],\n",
              " [26, 15, 138, 6, 64],\n",
              " [152, 15, 83, 95, 59],\n",
              " [2, 66, 12, 217, 6, 67, 3],\n",
              " [284, 285],\n",
              " [32, 62, 35, 325, 39],\n",
              " [84, 12, 475, 3],\n",
              " [185, 188, 24, 4, 504, 505, 29, 45, 506],\n",
              " [59, 5, 76, 493, 116, 25],\n",
              " [89, 37, 18, 548, 9, 35, 105],\n",
              " [17, 96, 251, 3],\n",
              " [61, 275, 481, 6, 57],\n",
              " [312, 2, 565, 1],\n",
              " [8, 71, 183, 25, 1, 19, 405, 181],\n",
              " [143, 34, 136, 91],\n",
              " [15, 72, 56, 32, 626, 140],\n",
              " [327, 7, 189, 3, 259],\n",
              " [13, 616, 14, 617, 27, 4, 16],\n",
              " [7, 188, 30, 499, 127],\n",
              " [72, 14, 641, 27, 4, 16],\n",
              " [186],\n",
              " [43, 12, 203, 63, 152, 39],\n",
              " [69, 76, 249, 1, 5],\n",
              " [11, 22, 9, 49, 4, 74, 171, 42, 53, 34],\n",
              " [24, 533, 30, 303],\n",
              " [60, 18, 298, 63, 583, 20, 3, 584, 1],\n",
              " [43, 65, 30, 303, 49, 9, 4, 38, 25, 1],\n",
              " [118, 40, 120, 68, 38],\n",
              " [288, 288, 179, 254, 487, 24],\n",
              " [168, 18, 333, 222, 7, 334, 30, 335, 127, 73],\n",
              " [21, 28, 14, 65, 216, 3, 25, 1, 22, 22],\n",
              " [7, 15, 137, 376, 23, 5],\n",
              " [134, 30, 210],\n",
              " [211, 4, 54, 29, 214, 593],\n",
              " [63, 122, 6, 140, 81],\n",
              " [129, 248, 3, 17],\n",
              " [96, 182, 112, 500, 169, 133, 501, 1],\n",
              " [11, 198, 19, 6, 64, 68],\n",
              " [51, 5, 680, 681, 77, 682, 215, 215, 114, 3, 23, 78],\n",
              " [15, 324, 141, 4, 657],\n",
              " [32, 62, 55, 4, 163, 1],\n",
              " [170, 22, 171, 12, 26, 343, 344, 42, 86, 1],\n",
              " [13, 14, 213, 257, 16],\n",
              " [326, 5, 238, 10, 88, 135, 3, 100],\n",
              " [35, 2, 556, 1],\n",
              " [36, 81, 40, 8, 123, 12, 1],\n",
              " [2, 105, 5, 218, 33, 162, 1],\n",
              " [50, 22, 22, 373, 45, 25, 1],\n",
              " [7, 205, 1],\n",
              " [8, 27, 15, 72, 16],\n",
              " [155, 31],\n",
              " [54, 44, 42, 3, 300, 26],\n",
              " [284, 285, 2, 20, 80, 1, 61],\n",
              " [62, 27, 168, 10, 20, 177, 242],\n",
              " [15, 54, 44, 175],\n",
              " [410, 1, 2],\n",
              " [24, 63, 568, 23, 60],\n",
              " [61, 34, 474, 6, 57],\n",
              " [326, 5, 40, 28, 319, 3, 95],\n",
              " [40, 15, 45, 4, 38, 239, 1],\n",
              " [93, 2, 32, 87, 435, 49, 25, 1],\n",
              " [128, 172, 162, 6, 35, 68, 42, 6],\n",
              " [11, 48, 76, 235, 4, 236, 61],\n",
              " [420],\n",
              " [32, 17, 10, 8, 377, 1],\n",
              " [37, 181, 250, 4, 1],\n",
              " [13, 34, 313, 33, 16],\n",
              " [87, 356, 224, 228, 357, 131, 358],\n",
              " [24, 62, 655, 139],\n",
              " [89, 296, 116, 514, 144, 29, 9],\n",
              " [62, 7, 104, 4, 39],\n",
              " [476, 477],\n",
              " [41, 29, 1, 518, 4, 21, 47, 9],\n",
              " [320, 13, 16],\n",
              " [17, 34, 102, 3],\n",
              " [15, 72, 178, 16],\n",
              " [635, 97, 320, 1],\n",
              " [225, 226, 21, 29, 352],\n",
              " [118, 5, 2, 454, 236, 1, 61],\n",
              " [113, 34, 49, 130, 11, 22, 181],\n",
              " [223, 185, 15, 19, 12, 39, 156, 208, 45, 4, 25],\n",
              " [28, 9, 8, 202, 74],\n",
              " [2, 55, 1],\n",
              " [54, 44, 11, 33, 55, 230],\n",
              " [59, 2, 97, 1],\n",
              " [118, 151, 12, 120, 83, 197],\n",
              " [212, 9, 153, 159, 112, 1, 2],\n",
              " [24, 640, 139],\n",
              " [647, 323, 16],\n",
              " [21, 77, 11, 122, 158, 16],\n",
              " [286],\n",
              " [292, 260, 54, 44, 1, 42, 53, 12],\n",
              " [15, 606, 10, 63, 607, 39],\n",
              " [646, 72, 16],\n",
              " [128, 136, 6, 57],\n",
              " [157, 51, 280, 467],\n",
              " [118],\n",
              " [26, 169, 54, 44, 210],\n",
              " [157, 282, 473, 200],\n",
              " [60, 14, 97, 105],\n",
              " [51, 671, 36],\n",
              " [93, 378, 112, 217, 172, 70],\n",
              " [4, 354, 29, 73, 129, 355],\n",
              " [5, 2, 108, 31, 1],\n",
              " [41, 20, 14, 4, 1, 7, 37],\n",
              " [51, 59, 154, 68, 3, 48, 23],\n",
              " [52, 19, 4, 121],\n",
              " [7, 50, 576, 111, 577],\n",
              " [137, 179, 100],\n",
              " [667, 668, 1, 35, 160, 44, 669, 4, 80, 213],\n",
              " [51, 59, 2, 55, 1],\n",
              " [149, 194, 26, 43, 52, 19, 3, 23],\n",
              " [123, 53, 18, 46, 58],\n",
              " [37, 10, 41, 123, 4, 190],\n",
              " [2, 66, 249, 1],\n",
              " [409, 14, 96, 66, 50, 1, 75],\n",
              " [510, 10, 209, 12, 294, 28, 295, 19, 86],\n",
              " [120, 2, 71, 559, 560],\n",
              " [419, 66],\n",
              " [7, 15, 604, 10, 71, 317, 19, 4, 121],\n",
              " [422, 41, 49, 9, 4, 234, 2, 186],\n",
              " [625, 35, 314, 28, 19, 3, 126, 16],\n",
              " [8, 685, 117, 24, 99, 328],\n",
              " [154, 611, 39, 156, 141],\n",
              " [206, 55, 111, 27, 207],\n",
              " [92, 340, 31, 109, 110, 341],\n",
              " [2, 396, 1, 7],\n",
              " [258, 125, 30, 3, 259, 1, 438, 37],\n",
              " [8, 114, 184, 1, 7, 37],\n",
              " [227, 87, 68, 42, 351],\n",
              " [8, 33, 108, 50, 1, 75],\n",
              " [41, 48, 345, 67, 3, 5],\n",
              " [271],\n",
              " [32, 237, 10, 35, 104, 39, 5],\n",
              " [41, 48, 4, 421, 173],\n",
              " [73, 261, 449, 117, 219, 31, 10],\n",
              " [304, 2, 86, 49, 4, 38, 25, 1],\n",
              " [277, 155],\n",
              " [5, 41, 442, 33, 4, 141, 25],\n",
              " [5, 24, 8, 114, 3, 23, 78],\n",
              " [124, 79, 540, 541, 13, 1, 306, 110, 24],\n",
              " [97, 2, 571, 1],\n",
              " [232, 31, 10, 276, 103, 1],\n",
              " [41, 202, 318, 74],\n",
              " [32, 28, 14, 52, 83, 23, 59],\n",
              " [399, 165, 3, 17, 173],\n",
              " [58, 73, 103, 91],\n",
              " [40, 28, 294, 612, 319, 3, 95],\n",
              " [13, 98, 56, 161, 256, 106, 150],\n",
              " [165, 397, 244, 1, 89, 37, 56],\n",
              " [7, 13, 27, 1],\n",
              " [675, 5, 676, 3, 95],\n",
              " [15, 98, 56, 238, 10, 138, 6, 57],\n",
              " [21, 47, 9, 69, 517, 297, 1],\n",
              " [63, 570, 1],\n",
              " [32, 34, 7, 50, 8, 27, 191, 1],\n",
              " [102],\n",
              " [271, 272],\n",
              " [26, 128, 162, 172, 6, 35, 174, 42, 6],\n",
              " [13, 323, 621, 4, 16],\n",
              " [21, 47, 10, 29, 30, 507, 100],\n",
              " [511, 512, 2, 1, 107, 513, 159, 9],\n",
              " [329, 31, 49, 18, 312, 1],\n",
              " [15, 98, 56, 161, 622, 623, 624],\n",
              " [275, 465, 3, 23, 26],\n",
              " [41, 134, 142, 64, 5, 12, 289, 528],\n",
              " [72, 56, 138, 6, 57],\n",
              " [68, 11, 43, 14, 52, 19, 70],\n",
              " [24, 322, 139],\n",
              " [69, 461, 13, 16],\n",
              " [589, 9, 590, 12, 255, 63, 591, 3, 592, 1],\n",
              " [309, 544, 9, 153, 159, 112, 1, 2],\n",
              " [40, 65, 3, 197, 2],\n",
              " [151, 12, 120, 83, 197, 119],\n",
              " [566, 296, 12, 28, 12, 52, 177, 64, 567, 10, 212, 12],\n",
              " [327, 7, 3, 664, 5],\n",
              " [2, 60, 549, 164],\n",
              " [7, 50, 8, 670, 183, 23, 1, 5],\n",
              " [436, 32, 178, 437, 1, 2],\n",
              " [665, 315, 10, 160, 31, 4, 666],\n",
              " [2, 92, 302, 21, 47, 12, 526, 301],\n",
              " [151, 9, 79, 48, 13, 19, 6, 64],\n",
              " [248],\n",
              " [96, 192, 28, 30, 211, 529],\n",
              " [237, 77, 11, 22, 9, 49, 9, 4, 372, 2],\n",
              " [119, 32, 192, 28, 83]]"
            ]
          },
          "execution_count": 12,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train_seq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "iLO5BDDaffdU"
      },
      "outputs": [],
      "source": [
        "X_train_seq_pad = pad_sequences(X_train_seq, maxlen=max_length, padding='post')\n",
        "X_test_seq_pad = pad_sequences(X_test_seq, maxlen=max_length,padding='post')\n",
        "X_val_seq_pad = pad_sequences(X_val_seq, maxlen=max_length,padding='post')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "xNDBIRzEpkpr"
      },
      "outputs": [],
      "source": [
        "#padding the sequences to make all the input sequences of the same length\n",
        "le = LabelEncoder()\n",
        "y_train_le = le.fit_transform(y_train)\n",
        "y_test_le = le.transform(y_test)\n",
        "y_val_le = le.transform(y_val)\n",
        "y_train_oh = to_categorical(y_train_le)\n",
        "y_test_oh = to_categorical(y_test_le)\n",
        "y_val_oh = to_categorical(y_val_le)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "colab_type": "code",
        "id": "_-2incjhqGh9",
        "outputId": "2717892a-c895-42df-ed21-45285868e2fe"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[457, 458,  60, ...,   0,   0,   0],\n",
              "       [145,  75,   0, ...,   0,   0,   0],\n",
              "       [  5,  22,  22, ...,   0,   0,   0],\n",
              "       ...,\n",
              "       [ 96, 192,  28, ...,   0,   0,   0],\n",
              "       [237,  77,  11, ...,   0,   0,   0],\n",
              "       [119,  32, 192, ...,   0,   0,   0]], dtype=int32)"
            ]
          },
          "execution_count": 15,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train_seq_pad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "colab_type": "code",
        "id": "WvKC3k3gramR",
        "outputId": "a196f06f-1910-42ce-e86e-6cf6427e2408"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Train on 370 samples, validate on 66 samples\n",
            "Epoch 1/128\n",
            "370/370 [==============================] - 1s 3ms/sample - loss: 1.4021 - acc: 0.2297 - val_loss: 1.4013 - val_acc: 0.1212\n",
            "Epoch 2/128\n",
            "370/370 [==============================] - 0s 232us/sample - loss: 1.3962 - acc: 0.2757 - val_loss: 1.3984 - val_acc: 0.1212\n",
            "Epoch 3/128\n",
            "370/370 [==============================] - 0s 222us/sample - loss: 1.3924 - acc: 0.2811 - val_loss: 1.3958 - val_acc: 0.1212\n",
            "Epoch 4/128\n",
            "370/370 [==============================] - 0s 282us/sample - loss: 1.3898 - acc: 0.2784 - val_loss: 1.3937 - val_acc: 0.1212\n",
            "Epoch 5/128\n",
            "370/370 [==============================] - 0s 220us/sample - loss: 1.3866 - acc: 0.2838 - val_loss: 1.3917 - val_acc: 0.1212\n",
            "Epoch 6/128\n",
            "370/370 [==============================] - 0s 214us/sample - loss: 1.3855 - acc: 0.3081 - val_loss: 1.3895 - val_acc: 0.1212\n",
            "Epoch 7/128\n",
            "370/370 [==============================] - 0s 229us/sample - loss: 1.3854 - acc: 0.2865 - val_loss: 1.3876 - val_acc: 0.1212\n",
            "Epoch 8/128\n",
            "370/370 [==============================] - 0s 233us/sample - loss: 1.3833 - acc: 0.2514 - val_loss: 1.3859 - val_acc: 0.1212\n",
            "Epoch 9/128\n",
            "370/370 [==============================] - 0s 214us/sample - loss: 1.3835 - acc: 0.2892 - val_loss: 1.3842 - val_acc: 0.3939\n",
            "Epoch 10/128\n",
            "370/370 [==============================] - 0s 221us/sample - loss: 1.3836 - acc: 0.2676 - val_loss: 1.3827 - val_acc: 0.3939\n",
            "Epoch 11/128\n",
            "370/370 [==============================] - 0s 226us/sample - loss: 1.3801 - acc: 0.3108 - val_loss: 1.3815 - val_acc: 0.3939\n",
            "Epoch 12/128\n",
            "370/370 [==============================] - 0s 221us/sample - loss: 1.3794 - acc: 0.3000 - val_loss: 1.3807 - val_acc: 0.3939\n",
            "Epoch 13/128\n",
            "370/370 [==============================] - 0s 230us/sample - loss: 1.3787 - acc: 0.2892 - val_loss: 1.3801 - val_acc: 0.3939\n",
            "Epoch 14/128\n",
            "370/370 [==============================] - 0s 249us/sample - loss: 1.3770 - acc: 0.3108 - val_loss: 1.3797 - val_acc: 0.3939\n",
            "Epoch 15/128\n",
            "370/370 [==============================] - 0s 227us/sample - loss: 1.3810 - acc: 0.2730 - val_loss: 1.3794 - val_acc: 0.3939\n",
            "Epoch 16/128\n",
            "370/370 [==============================] - 0s 220us/sample - loss: 1.3767 - acc: 0.2622 - val_loss: 1.3790 - val_acc: 0.4091\n",
            "Epoch 17/128\n",
            "370/370 [==============================] - 0s 228us/sample - loss: 1.3777 - acc: 0.3054 - val_loss: 1.3790 - val_acc: 0.3788\n",
            "Epoch 18/128\n",
            "370/370 [==============================] - 0s 221us/sample - loss: 1.3751 - acc: 0.3135 - val_loss: 1.3789 - val_acc: 0.1212\n",
            "Epoch 19/128\n",
            "370/370 [==============================] - 0s 244us/sample - loss: 1.3713 - acc: 0.3000 - val_loss: 1.3783 - val_acc: 0.1212\n",
            "Epoch 20/128\n",
            "370/370 [==============================] - 0s 219us/sample - loss: 1.3706 - acc: 0.2946 - val_loss: 1.3771 - val_acc: 0.1212\n",
            "Epoch 21/128\n",
            "370/370 [==============================] - 0s 225us/sample - loss: 1.3657 - acc: 0.3189 - val_loss: 1.3747 - val_acc: 0.1212\n",
            "Epoch 22/128\n",
            "370/370 [==============================] - 0s 246us/sample - loss: 1.3587 - acc: 0.3189 - val_loss: 1.3697 - val_acc: 0.3182\n",
            "Epoch 23/128\n",
            "370/370 [==============================] - 0s 236us/sample - loss: 1.3505 - acc: 0.3459 - val_loss: 1.3622 - val_acc: 0.3788\n",
            "Epoch 24/128\n",
            "370/370 [==============================] - 0s 218us/sample - loss: 1.3418 - acc: 0.3243 - val_loss: 1.3512 - val_acc: 0.3788\n",
            "Epoch 25/128\n",
            "370/370 [==============================] - 0s 216us/sample - loss: 1.3194 - acc: 0.4108 - val_loss: 1.3344 - val_acc: 0.4091\n",
            "Epoch 26/128\n",
            "370/370 [==============================] - 0s 223us/sample - loss: 1.3080 - acc: 0.4108 - val_loss: 1.3103 - val_acc: 0.3636\n",
            "Epoch 27/128\n",
            "370/370 [==============================] - 0s 227us/sample - loss: 1.2567 - acc: 0.4919 - val_loss: 1.2747 - val_acc: 0.4545\n",
            "Epoch 28/128\n",
            "370/370 [==============================] - 0s 218us/sample - loss: 1.2187 - acc: 0.5108 - val_loss: 1.2337 - val_acc: 0.4242\n",
            "Epoch 29/128\n",
            "370/370 [==============================] - 0s 224us/sample - loss: 1.1740 - acc: 0.5297 - val_loss: 1.1947 - val_acc: 0.4545\n",
            "Epoch 30/128\n",
            "370/370 [==============================] - 0s 216us/sample - loss: 1.1281 - acc: 0.5324 - val_loss: 1.1651 - val_acc: 0.3939\n",
            "Epoch 31/128\n",
            "370/370 [==============================] - 0s 259us/sample - loss: 1.0720 - acc: 0.5405 - val_loss: 1.1545 - val_acc: 0.3636\n",
            "Epoch 32/128\n",
            "370/370 [==============================] - 0s 226us/sample - loss: 1.0155 - acc: 0.5541 - val_loss: 1.1476 - val_acc: 0.3788\n",
            "Epoch 33/128\n",
            "370/370 [==============================] - 0s 218us/sample - loss: 0.9885 - acc: 0.5676 - val_loss: 1.1469 - val_acc: 0.3485\n",
            "Epoch 34/128\n",
            "370/370 [==============================] - 0s 227us/sample - loss: 0.9320 - acc: 0.5730 - val_loss: 1.1571 - val_acc: 0.3333\n",
            "Epoch 35/128\n",
            "370/370 [==============================] - 0s 263us/sample - loss: 0.9343 - acc: 0.5486 - val_loss: 1.1607 - val_acc: 0.3788\n",
            "Epoch 36/128\n",
            "370/370 [==============================] - 0s 223us/sample - loss: 0.9095 - acc: 0.5730 - val_loss: 1.1489 - val_acc: 0.4091\n",
            "Epoch 37/128\n",
            "370/370 [==============================] - 0s 236us/sample - loss: 0.8955 - acc: 0.5919 - val_loss: 1.1412 - val_acc: 0.3939\n",
            "Epoch 38/128\n",
            "370/370 [==============================] - 0s 217us/sample - loss: 0.8805 - acc: 0.5892 - val_loss: 1.1690 - val_acc: 0.3636\n",
            "Epoch 39/128\n",
            "370/370 [==============================] - 0s 221us/sample - loss: 0.8540 - acc: 0.6270 - val_loss: 1.1756 - val_acc: 0.3485\n",
            "Epoch 40/128\n",
            "370/370 [==============================] - 0s 226us/sample - loss: 0.8340 - acc: 0.6054 - val_loss: 1.1649 - val_acc: 0.3636\n",
            "Epoch 41/128\n",
            "370/370 [==============================] - 0s 229us/sample - loss: 0.8154 - acc: 0.6324 - val_loss: 1.1216 - val_acc: 0.4697\n",
            "Epoch 42/128\n",
            "370/370 [==============================] - 0s 270us/sample - loss: 0.7728 - acc: 0.6622 - val_loss: 1.1204 - val_acc: 0.4697\n",
            "Epoch 43/128\n",
            "370/370 [==============================] - 0s 249us/sample - loss: 0.7487 - acc: 0.6865 - val_loss: 1.1364 - val_acc: 0.4697\n",
            "Epoch 44/128\n",
            "370/370 [==============================] - 0s 236us/sample - loss: 0.7249 - acc: 0.7054 - val_loss: 1.1304 - val_acc: 0.4697\n",
            "Epoch 45/128\n",
            "370/370 [==============================] - 0s 231us/sample - loss: 0.7339 - acc: 0.7081 - val_loss: 1.1659 - val_acc: 0.4545\n",
            "Epoch 46/128\n",
            "370/370 [==============================] - 0s 238us/sample - loss: 0.7194 - acc: 0.6865 - val_loss: 1.1794 - val_acc: 0.4394\n",
            "Epoch 47/128\n",
            "370/370 [==============================] - 0s 239us/sample - loss: 0.7047 - acc: 0.6919 - val_loss: 1.1674 - val_acc: 0.4697\n",
            "Epoch 48/128\n",
            "370/370 [==============================] - 0s 242us/sample - loss: 0.6489 - acc: 0.7270 - val_loss: 1.1859 - val_acc: 0.4848\n",
            "Epoch 49/128\n",
            "370/370 [==============================] - 0s 225us/sample - loss: 0.6612 - acc: 0.7297 - val_loss: 1.1688 - val_acc: 0.5000\n",
            "Epoch 50/128\n",
            "370/370 [==============================] - 0s 227us/sample - loss: 0.6349 - acc: 0.7351 - val_loss: 1.1483 - val_acc: 0.5152\n",
            "Epoch 51/128\n",
            "370/370 [==============================] - 0s 216us/sample - loss: 0.6267 - acc: 0.7351 - val_loss: 1.1783 - val_acc: 0.5455\n",
            "Epoch 52/128\n",
            "370/370 [==============================] - 0s 225us/sample - loss: 0.5962 - acc: 0.7973 - val_loss: 1.2104 - val_acc: 0.5303\n",
            "Epoch 53/128\n",
            "370/370 [==============================] - 0s 251us/sample - loss: 0.5838 - acc: 0.7703 - val_loss: 1.1799 - val_acc: 0.5606\n",
            "Epoch 54/128\n",
            "370/370 [==============================] - 0s 236us/sample - loss: 0.5608 - acc: 0.8027 - val_loss: 1.1657 - val_acc: 0.5606\n",
            "Epoch 55/128\n",
            "370/370 [==============================] - 0s 240us/sample - loss: 0.5122 - acc: 0.8351 - val_loss: 1.1556 - val_acc: 0.5758\n",
            "Epoch 56/128\n",
            "370/370 [==============================] - 0s 240us/sample - loss: 0.4848 - acc: 0.8568 - val_loss: 1.2162 - val_acc: 0.5606\n",
            "Epoch 57/128\n",
            "370/370 [==============================] - 0s 233us/sample - loss: 0.5010 - acc: 0.8514 - val_loss: 1.2269 - val_acc: 0.5303\n",
            "Epoch 58/128\n",
            "370/370 [==============================] - 0s 235us/sample - loss: 0.4482 - acc: 0.8730 - val_loss: 1.1910 - val_acc: 0.5909\n",
            "Epoch 59/128\n",
            "370/370 [==============================] - 0s 248us/sample - loss: 0.4064 - acc: 0.8919 - val_loss: 1.1436 - val_acc: 0.6061\n",
            "Epoch 60/128\n",
            "370/370 [==============================] - 0s 235us/sample - loss: 0.4000 - acc: 0.9000 - val_loss: 1.1220 - val_acc: 0.6212\n",
            "Epoch 61/128\n",
            "370/370 [==============================] - 0s 238us/sample - loss: 0.4051 - acc: 0.8946 - val_loss: 1.1287 - val_acc: 0.6364\n",
            "Epoch 62/128\n",
            "370/370 [==============================] - 0s 228us/sample - loss: 0.3694 - acc: 0.8973 - val_loss: 1.1408 - val_acc: 0.6061\n",
            "Epoch 63/128\n",
            "370/370 [==============================] - 0s 226us/sample - loss: 0.3730 - acc: 0.8838 - val_loss: 1.1565 - val_acc: 0.6364\n",
            "Epoch 64/128\n",
            "370/370 [==============================] - 0s 266us/sample - loss: 0.3410 - acc: 0.9108 - val_loss: 1.1651 - val_acc: 0.6364\n",
            "Epoch 65/128\n",
            "370/370 [==============================] - 0s 264us/sample - loss: 0.3090 - acc: 0.9216 - val_loss: 1.1628 - val_acc: 0.6515\n",
            "Epoch 66/128\n",
            "370/370 [==============================] - 0s 244us/sample - loss: 0.3100 - acc: 0.9216 - val_loss: 1.1543 - val_acc: 0.6515\n",
            "Epoch 67/128\n",
            "370/370 [==============================] - 0s 233us/sample - loss: 0.2660 - acc: 0.9541 - val_loss: 1.1665 - val_acc: 0.6515\n",
            "Epoch 68/128\n",
            "370/370 [==============================] - 0s 230us/sample - loss: 0.2820 - acc: 0.9432 - val_loss: 1.1580 - val_acc: 0.6515\n",
            "Epoch 69/128\n",
            "370/370 [==============================] - 0s 235us/sample - loss: 0.2422 - acc: 0.9595 - val_loss: 1.1593 - val_acc: 0.6515\n",
            "Epoch 70/128\n",
            "370/370 [==============================] - 0s 252us/sample - loss: 0.2757 - acc: 0.9324 - val_loss: 1.1746 - val_acc: 0.6515\n",
            "Epoch 71/128\n",
            "370/370 [==============================] - 0s 232us/sample - loss: 0.2452 - acc: 0.9514 - val_loss: 1.1933 - val_acc: 0.6515\n",
            "Epoch 72/128\n",
            "370/370 [==============================] - 0s 228us/sample - loss: 0.2223 - acc: 0.9622 - val_loss: 1.2039 - val_acc: 0.6364\n",
            "Epoch 73/128\n",
            "370/370 [==============================] - 0s 220us/sample - loss: 0.2205 - acc: 0.9541 - val_loss: 1.2019 - val_acc: 0.6515\n",
            "Epoch 74/128\n",
            "370/370 [==============================] - 0s 228us/sample - loss: 0.2381 - acc: 0.9486 - val_loss: 1.2297 - val_acc: 0.6515\n",
            "Epoch 75/128\n",
            "370/370 [==============================] - 0s 244us/sample - loss: 0.2067 - acc: 0.9622 - val_loss: 1.2735 - val_acc: 0.6515\n",
            "Epoch 76/128\n",
            "370/370 [==============================] - 0s 243us/sample - loss: 0.1855 - acc: 0.9730 - val_loss: 1.3143 - val_acc: 0.6212\n",
            "Epoch 77/128\n",
            "370/370 [==============================] - 0s 239us/sample - loss: 0.2329 - acc: 0.9514 - val_loss: 1.3024 - val_acc: 0.6364\n",
            "Epoch 78/128\n",
            "370/370 [==============================] - 0s 242us/sample - loss: 0.1894 - acc: 0.9622 - val_loss: 1.2455 - val_acc: 0.6818\n",
            "Epoch 79/128\n",
            "370/370 [==============================] - 0s 254us/sample - loss: 0.1735 - acc: 0.9676 - val_loss: 1.2349 - val_acc: 0.6667\n",
            "Epoch 80/128\n",
            "370/370 [==============================] - 0s 235us/sample - loss: 0.2179 - acc: 0.9514 - val_loss: 1.2228 - val_acc: 0.6667\n",
            "Epoch 81/128\n",
            "370/370 [==============================] - 0s 263us/sample - loss: 0.1734 - acc: 0.9703 - val_loss: 1.2276 - val_acc: 0.6667\n",
            "Epoch 82/128\n",
            "370/370 [==============================] - 0s 240us/sample - loss: 0.1413 - acc: 0.9811 - val_loss: 1.2397 - val_acc: 0.6667\n",
            "Epoch 83/128\n",
            "370/370 [==============================] - 0s 249us/sample - loss: 0.1538 - acc: 0.9784 - val_loss: 1.2513 - val_acc: 0.6667\n",
            "Epoch 84/128\n",
            "370/370 [==============================] - 0s 231us/sample - loss: 0.1668 - acc: 0.9676 - val_loss: 1.2990 - val_acc: 0.6818\n",
            "Epoch 85/128\n",
            "370/370 [==============================] - 0s 236us/sample - loss: 0.1552 - acc: 0.9784 - val_loss: 1.3377 - val_acc: 0.6515\n",
            "Epoch 86/128\n",
            "370/370 [==============================] - 0s 276us/sample - loss: 0.1352 - acc: 0.9784 - val_loss: 1.3512 - val_acc: 0.6515\n",
            "Epoch 87/128\n",
            "370/370 [==============================] - 0s 247us/sample - loss: 0.1500 - acc: 0.9757 - val_loss: 1.3359 - val_acc: 0.6667\n",
            "Epoch 88/128\n",
            "370/370 [==============================] - 0s 245us/sample - loss: 0.1446 - acc: 0.9730 - val_loss: 1.3377 - val_acc: 0.6667\n",
            "Epoch 89/128\n",
            "370/370 [==============================] - 0s 233us/sample - loss: 0.1166 - acc: 0.9811 - val_loss: 1.3247 - val_acc: 0.6667\n",
            "Epoch 90/128\n",
            "370/370 [==============================] - 0s 232us/sample - loss: 0.1238 - acc: 0.9730 - val_loss: 1.3521 - val_acc: 0.6515\n",
            "Epoch 91/128\n",
            "370/370 [==============================] - 0s 244us/sample - loss: 0.1117 - acc: 0.9811 - val_loss: 1.3797 - val_acc: 0.6364\n",
            "Epoch 92/128\n",
            "370/370 [==============================] - 0s 238us/sample - loss: 0.1186 - acc: 0.9784 - val_loss: 1.4082 - val_acc: 0.6364\n",
            "Epoch 93/128\n",
            "370/370 [==============================] - 0s 238us/sample - loss: 0.1398 - acc: 0.9676 - val_loss: 1.3897 - val_acc: 0.6515\n",
            "Epoch 94/128\n",
            "370/370 [==============================] - 0s 237us/sample - loss: 0.1297 - acc: 0.9838 - val_loss: 1.3856 - val_acc: 0.6515\n",
            "Epoch 95/128\n",
            "370/370 [==============================] - 0s 243us/sample - loss: 0.1201 - acc: 0.9784 - val_loss: 1.3802 - val_acc: 0.6667\n",
            "Epoch 96/128\n",
            "370/370 [==============================] - 0s 242us/sample - loss: 0.1331 - acc: 0.9703 - val_loss: 1.3727 - val_acc: 0.6515\n",
            "Epoch 97/128\n",
            "370/370 [==============================] - 0s 265us/sample - loss: 0.1080 - acc: 0.9865 - val_loss: 1.3731 - val_acc: 0.6364\n",
            "Epoch 98/128\n",
            "370/370 [==============================] - 0s 275us/sample - loss: 0.1034 - acc: 0.9865 - val_loss: 1.3763 - val_acc: 0.6515\n",
            "Epoch 99/128\n",
            "370/370 [==============================] - 0s 243us/sample - loss: 0.0995 - acc: 0.9865 - val_loss: 1.4048 - val_acc: 0.6515\n",
            "Epoch 100/128\n",
            "370/370 [==============================] - 0s 232us/sample - loss: 0.0950 - acc: 0.9892 - val_loss: 1.4087 - val_acc: 0.6515\n",
            "Epoch 101/128\n",
            "370/370 [==============================] - 0s 232us/sample - loss: 0.1109 - acc: 0.9811 - val_loss: 1.4080 - val_acc: 0.6515\n",
            "Epoch 102/128\n",
            "370/370 [==============================] - 0s 237us/sample - loss: 0.0792 - acc: 0.9973 - val_loss: 1.4152 - val_acc: 0.6667\n",
            "Epoch 103/128\n",
            "370/370 [==============================] - 0s 228us/sample - loss: 0.1100 - acc: 0.9784 - val_loss: 1.4631 - val_acc: 0.6515\n",
            "Epoch 104/128\n",
            "370/370 [==============================] - 0s 220us/sample - loss: 0.0774 - acc: 0.9919 - val_loss: 1.4792 - val_acc: 0.6515\n",
            "Epoch 105/128\n",
            "370/370 [==============================] - 0s 237us/sample - loss: 0.0762 - acc: 0.9973 - val_loss: 1.4918 - val_acc: 0.6667\n",
            "Epoch 106/128\n",
            "370/370 [==============================] - 0s 251us/sample - loss: 0.0870 - acc: 0.9946 - val_loss: 1.4705 - val_acc: 0.6818\n",
            "Epoch 107/128\n",
            "370/370 [==============================] - 0s 223us/sample - loss: 0.0930 - acc: 0.9784 - val_loss: 1.4723 - val_acc: 0.6818\n",
            "Epoch 108/128\n",
            "370/370 [==============================] - 0s 271us/sample - loss: 0.0710 - acc: 0.9973 - val_loss: 1.4680 - val_acc: 0.6818\n",
            "Epoch 109/128\n",
            "370/370 [==============================] - 0s 224us/sample - loss: 0.0802 - acc: 0.9865 - val_loss: 1.4702 - val_acc: 0.6818\n",
            "Epoch 110/128\n",
            "370/370 [==============================] - 0s 250us/sample - loss: 0.0937 - acc: 0.9865 - val_loss: 1.5026 - val_acc: 0.6667\n",
            "Epoch 111/128\n",
            "370/370 [==============================] - 0s 237us/sample - loss: 0.0815 - acc: 0.9919 - val_loss: 1.5172 - val_acc: 0.6515\n",
            "Epoch 112/128\n",
            "370/370 [==============================] - 0s 232us/sample - loss: 0.0710 - acc: 0.9919 - val_loss: 1.5225 - val_acc: 0.6515\n",
            "Epoch 113/128\n",
            "370/370 [==============================] - 0s 226us/sample - loss: 0.0830 - acc: 0.9811 - val_loss: 1.4959 - val_acc: 0.6515\n",
            "Epoch 114/128\n",
            "370/370 [==============================] - 0s 261us/sample - loss: 0.0862 - acc: 0.9838 - val_loss: 1.3963 - val_acc: 0.6970\n",
            "Epoch 115/128\n",
            "370/370 [==============================] - 0s 247us/sample - loss: 0.0992 - acc: 0.9811 - val_loss: 1.3488 - val_acc: 0.6970\n",
            "Epoch 116/128\n",
            "370/370 [==============================] - 0s 227us/sample - loss: 0.0661 - acc: 0.9973 - val_loss: 1.3464 - val_acc: 0.7273\n",
            "Epoch 117/128\n",
            "370/370 [==============================] - 0s 228us/sample - loss: 0.0825 - acc: 0.9865 - val_loss: 1.3404 - val_acc: 0.7273\n",
            "Epoch 118/128\n",
            "370/370 [==============================] - 0s 244us/sample - loss: 0.1325 - acc: 0.9730 - val_loss: 1.3360 - val_acc: 0.7273\n",
            "Epoch 119/128\n",
            "370/370 [==============================] - 0s 252us/sample - loss: 0.1420 - acc: 0.9622 - val_loss: 1.3529 - val_acc: 0.7121\n",
            "Epoch 120/128\n",
            "370/370 [==============================] - 0s 269us/sample - loss: 0.0805 - acc: 0.9892 - val_loss: 1.3338 - val_acc: 0.7121\n",
            "Epoch 121/128\n",
            "370/370 [==============================] - 0s 263us/sample - loss: 0.0724 - acc: 0.9919 - val_loss: 1.3434 - val_acc: 0.7121\n",
            "Epoch 122/128\n",
            "370/370 [==============================] - 0s 247us/sample - loss: 0.0839 - acc: 0.9892 - val_loss: 1.4087 - val_acc: 0.6970\n",
            "Epoch 123/128\n",
            "370/370 [==============================] - 0s 239us/sample - loss: 0.0795 - acc: 0.9892 - val_loss: 1.4533 - val_acc: 0.6667\n",
            "Epoch 124/128\n",
            "370/370 [==============================] - 0s 233us/sample - loss: 0.0767 - acc: 0.9919 - val_loss: 1.4518 - val_acc: 0.6667\n",
            "Epoch 125/128\n",
            "370/370 [==============================] - 0s 230us/sample - loss: 0.0729 - acc: 0.9919 - val_loss: 1.4146 - val_acc: 0.6970\n",
            "Epoch 126/128\n",
            "370/370 [==============================] - 0s 242us/sample - loss: 0.0948 - acc: 0.9892 - val_loss: 1.3726 - val_acc: 0.6970\n",
            "Epoch 127/128\n",
            "370/370 [==============================] - 0s 229us/sample - loss: 0.0637 - acc: 0.9919 - val_loss: 1.3344 - val_acc: 0.7121\n",
            "Epoch 128/128\n",
            "370/370 [==============================] - 0s 250us/sample - loss: 0.0697 - acc: 0.9946 - val_loss: 1.3231 - val_acc: 0.7121\n"
          ]
        }
      ],
      "source": [
        "emb_dims = 256\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, emb_dims, input_length=max_length, embeddings_regularizer = tf.keras.regularizers.l2(0.0001)))\n",
        "model.add(LSTM(units = 16, dropout = 0.2,recurrent_dropout = 0.2))\n",
        "model.add(Dense(4, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(X_train_seq_pad, y_train_oh, epochs = 128, batch_size = 256, validation_data=(X_val_seq_pad, y_val_oh), shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "colab_type": "code",
        "id": "LvqZ-lxJyvuf",
        "outputId": "628776ef-e93f-4403-ecb2-33ba9e740e93"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "colab_type": "code",
        "id": "jJMNuByCRbBL",
        "outputId": "9a9fdaeb-cc72-4aae-cd0a-0d0d36c9a183"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 20, 256)           175616    \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 16)                17472     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 4)                 68        \n",
            "=================================================================\n",
            "Total params: 193,156\n",
            "Trainable params: 193,156\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "colab_type": "code",
        "id": "k6YKpCP3NQrd",
        "outputId": "39b4ac8b-ebd5-46b8-e44e-b1c4fa4e3051"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "77/77 [==============================] - 0s 504us/sample - loss: 1.9065 - acc: 0.6104\n",
            "/n\n",
            "Test accuracy of word embeddings model: 61.04%\n"
          ]
        }
      ],
      "source": [
        "results = model.evaluate(X_test_seq_pad, y_test_oh)\n",
        "print('/n')\n",
        "print('Test accuracy of word embeddings model: {0:.2f}%'.format(results[1]*100))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyNmNy9m3tP3OJJl6ZGVUEmi",
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "Hindi sentiment analysis.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
